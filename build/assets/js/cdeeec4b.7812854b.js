"use strict";(self.webpackChunklarf_site=self.webpackChunklarf_site||[]).push([[7778],{5680:(e,n,t)=>{t.d(n,{xA:()=>c,yg:()=>h});var a=t(6540);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,o=function(e,n){if(null==e)return{};var t,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var l=a.createContext({}),p=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},c=function(e){var n=p(e.components);return a.createElement(l.Provider,{value:n},e.children)},d="mdxType",g={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),d=p(t),u=o,h=d["".concat(l,".").concat(u)]||d[u]||g[u]||r;return t?a.createElement(h,i(i({ref:n},c),{},{components:t})):a.createElement(h,i({ref:n},c))}));function h(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var r=t.length,i=new Array(r);i[0]=u;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[d]="string"==typeof e?e:o,i[1]=s;for(var p=2;p<r;p++)i[p]=t[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},1254:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>g,frontMatter:()=>r,metadata:()=>s,toc:()=>p});var a=t(8168),o=(t(6540),t(5680));const r={sidebar_position:2},i="Instances",s={unversionedId:"toolkit/tokens/instances",id:"toolkit/tokens/instances",title:"Instances",description:"Instances",source:"@site/docs/toolkit/tokens/instances.md",sourceDirName:"toolkit/tokens",slug:"/toolkit/tokens/instances",permalink:"/docs/toolkit/tokens/instances",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/toolkit/tokens/instances.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Functions",permalink:"/docs/toolkit/tokens/functions"},next:{title:"References",permalink:"/docs/toolkit/tokens/references"}},l={},p=[{value:"Introduction",id:"introduction",level:3},{value:"Adding Types to your Language",id:"adding-types-to-your-language",level:3},{value:"Triggering Token Creation",id:"triggering-token-creation",level:3},{value:"Creating a Clone",id:"creating-a-clone",level:3},{value:"Handling Type Interactions",id:"handling-type-interactions",level:3}],c={toc:p},d="wrapper";function g(e){let{components:n,...r}=e;return(0,o.yg)(d,(0,a.A)({},c,r,{components:n,mdxType:"MDXLayout"}),(0,o.yg)("h1",{id:"instances"},"Instances"),(0,o.yg)("p",null,(0,o.yg)("img",{alt:"Instances",src:t(5468).A,width:"1462",height:"346"})),(0,o.yg)("admonition",{title:"Type System Suggestion",type:"tip"},(0,o.yg)("p",{parentName:"admonition"},"This section covers the implementation of one possible route for a type system created using LARF. Type support was purposefully\nleft ambigious to prevent the authors ideas of how types should operate and interfere with your own type ambitions. As such\nalthough the following represents one approach, this is not the only way you can approach it and is merely here as a\nguide for you to get started.")),(0,o.yg)("admonition",{title:"Walk before you run",type:"danger"},(0,o.yg)("p",{parentName:"admonition"},"Creating and handling types I would argue is one of the more challenging aspects to creating a language. I've tried to lay out in simple\nterms what is required below, but it is one of the more involved sections. As such, if you're new to LARF I would suggest becoming\nfamiliar with the basics before attempting this section.")),(0,o.yg)("h3",{id:"introduction"},"Introduction"),(0,o.yg)("p",null,"Token instances provide a route to implement and represent types (custom objects) within your language. It is important\nto understand that no strict type handling is written into LARF itself, instead it provides this interface to act as a\nguide when implementing your own type system. You are free to implement your own approach should you wish, but this guide\nwill take you through the steps to make use of the TokenInstance interface."),(0,o.yg)("h3",{id:"adding-types-to-your-language"},"Adding Types to your Language"),(0,o.yg)("p",null,"Firstly let's create a class which extends not only the standard Token class but also implements the TokenInstance\ninterface. An example of this can be seen below:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-java"},"public class MyTypeToken extends Token<Token<?>> implements TokenInstance {\n\n    //Standard Token Methods\n    //...\n\n    @Override\n    public PatternType getPatternType() {\n        return PatternType.GRAMMAR;\n    }\n\n    @Override\n    public String getPattern() {\n        return \"'type' val:String ( '(' ( val:String ','? )+? ')' )? ( '<-' val:String )? \"+\n                    \"[ multiLine ]\";\n    }      \n\n    @Override\n    protected List<Token<?>> process(LARFParser parser, LARFContext context, LARFConfig config) {\n        while (getTokenGroups().size() < 4) getTokenGroups().add(new TokenGroup());\n        if (getTokenGroups().get(0).getFlatTokens().size() != 1) {\n            throw new ParserException(String.format(\"Expected a single TokenValue for the \" +\n                    \"function name but found %d tokens provided\", \n                    getTokenGroups().get(0).getTokenPosition()));\n        }\n        String typeName = getTokenGroups().get(0).getFlatTokens().get(0).getValue().toString();\n\n        context.set(typeName, this, VariableType.PROTOTYPE);\n        return Collections.singletonList(new NullToken());\n    }    \n\n    //Will define the below later...\n\n    @Override\n    public Token<?> createInstance(LARFParser parser, LARFContext context, LARFConfig config, \n                                   String typeName) { ... }                                     \n\n    @Override\n    public List<Token<?>> process(Token<?> source, LARFParser parser, LARFContext context, \n                                  LARFConfig config, String target, List<Token<?>> params) \n                                  { ... }\n\n    @Override\n    public String getTypeName() { ... }    \n\n    @Override\n    public List<String> getDependencies() { ... }    \n\n}\n")),(0,o.yg)("p",null,"This may look confusing at first, but let's break each each part. Firstly let's look at the pattern:"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"'type'"),": This denotes that any type definition has to begin with the ",(0,o.yg)("inlineCode",{parentName:"li"},"type")," keyword."),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"val:String"),": A single capture group is expected for the name that is to be associated with the type e.g. MyType"),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"( ... )?"),": An optional capture group for the class parameters"),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"'(' ( val:String ','? )+? ')'"),": A pair of brackets surrounding an optional token group containing one or more\nString values separated by commas. Since this is being written for a typeless language, we are only expecting a name\nto be provided rather than a typed value. If you are defining a typed language then you could point the parameter\nimplementation using a grammar reference if you've defined one. For example, if I had a Token called TypedVariableToken\nwith a name defined as typedVariable, you could use ",(0,o.yg)("inlineCode",{parentName:"li"},"'(' ( [ typedVariable ] ','? )+? ')'"),". For our original typeless\ncase, an example of this would be ",(0,o.yg)("inlineCode",{parentName:"li"},"(a,b,c)"),". For a typed variant an example would be ",(0,o.yg)("inlineCode",{parentName:"li"},"(int a, String b, double c)"),"."),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"( '<-' val:String )?"),": An optional token group expecting a ",(0,o.yg)("inlineCode",{parentName:"li"},"<-")," fixed value with a String identifying the\ntype that is the parent. "),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"[ multiLine ]"),": Finally we define the body of the type which we suppose would contain one or more lines found\nbetween two delimiters or keywords e.g. ",(0,o.yg)("inlineCode",{parentName:"li"},"{ line1; line2; ... }"),".\nA full example for the above pattern would be:")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-java"},"type MyType(a,b,c) {\n    //Other tokens...\n}\n")),(0,o.yg)("p",null,"This is similar to the ",(0,o.yg)("inlineCode",{parentName:"p"},"record")," in Java where you can define a class and it's values using the list of parameters.\nNext let's look at the ",(0,o.yg)("inlineCode",{parentName:"p"},"process")," method. The first part is dedicated to the validation of the token groups and their\ncontent. It just checks to ensure that a name has been specified for the type. The next two lines are key:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-java"},"String typeName = getTokenGroups().get(0).getFlatTokens().get(0).getValue().toString();\n\ncontext.set(typeName, this, VariableType.PROTOTYPE);\n")),(0,o.yg)("p",null,"The first retrieves the name of the type found in the first capture group e.g. MyType. This is used as the unique identifier\nfor this type in context. It is also registered as a ",(0,o.yg)("inlineCode",{parentName:"p"},"VariableType.PROTOTYPE")," which means there can only ever be one. From\nthis other versions can be cloned, but a prototype is essentially the blueprint for the type as defined in the code."),(0,o.yg)("p",null,"In addition to the standard Token methods, there are several new methods that our new TypeToken class must implement. An\nexample of each will be defined later but for now I'll briefly describe what these methods do:"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"createInstance"),": Gets called by another token to invoke an instance of this type in the language. The token class from\nwhich this is triggered will typically use a keyword e.g. ",(0,o.yg)("inlineCode",{parentName:"li"},"new")," to trigger off this action. This will be described in a\nlater ",(0,o.yg)("a",{parentName:"li",href:"/docs/toolkit/tokens/instances#invoking-creation-from-a-defined-type"},"section")," on this page."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"process"),": An overloaded variant of the process method which accepts a target and list of parameters. This can be\nused when targetting a specific child resource on the object instance e.g. a method."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"getTypeName"),": Returns the unique identifier of the current object to store in context"),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"getDependencies"),": Provides a list of references to other type instances which this class extends / inherits.")),(0,o.yg)("h3",{id:"triggering-token-creation"},"Triggering Token Creation"),(0,o.yg)("p",null,"Now that we've got the shell of our type token defined, the next thing we'll want is a way to create an instance of that\ntype in our language. For this example we'll be copying Java's implementation and using the ",(0,o.yg)("inlineCode",{parentName:"p"},"new")," keyword. For this, we'll\ncreate a new CreateTypeToken class with the following definition:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-java"},'public class CreateTypeToken extends Token<Token<?>> {\n\n    public CreateTypeToken() {\n        super("createType", null);\n    }\n\n    @Override\n    public Token<Token<?>> createToken(String value) {\n        return cloneDefaultProperties(new CreateTypeToken());\n    }\n\n    @Override\n    public PatternType getPatternType() {\n        return PatternType.GRAMMAR;\n    }\n\n    @Override\n    public String getPattern() {\n        return "\'new\' val:String \'(\' ( expr \',\' )+ \')\'";\n    }\n\n    @Override\n    public Optional<String> getGuidance(String token, List<Integer> groupsCount) {\n        if (token.equalsIgnoreCase("("))\n            return Optional.of("A new keyword requires an open bracket to be defined for the " +\n                    "parameter list e.g. new MyType (<-- a, b, c )");\n        if (token.equalsIgnoreCase(")"))\n            return Optional.of("A new keyword requires a closing bracket to be defined for " +\n                    "the parameter list e.g. new MyType ( a, b, c )<--");\n        return Optional.empty();\n    }    \n\n    @Override\n    protected List<Token<?>> process(LARFParser parser, LARFContext context, LARFConfig config) { }\n}\n')),(0,o.yg)("p",null,"Given the pattern of our new Token, this means you can create new instances for a given type using ",(0,o.yg)("inlineCode",{parentName:"p"},"new CustomType(...)"),". If you're\nnot that familiar with grammar though, let's break it down to explain what is happening:"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"'new'"),": A fixed ",(0,o.yg)("inlineCode",{parentName:"li"},"new")," keyword to uniquely identify this token"),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"val:String"),": A single token capture group which is of String type. This means we're expecting a name to be specified and it will\nthrow an error if another Token or statement is provided."),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"'('"),": A fixed open bracket to denote the start of the list of parameters that is passed to the constructor of the type being\ntargetted. This could differ depending on your type implementation."),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"( expr ',' )+"),": A repeatable group containing a capture group for one or more tokens separated by commas. This would allow us to\ninvoke the Token with ",(0,o.yg)("inlineCode",{parentName:"li"},"new MyType(1 + 1,5,6)"),". If you used only val (single capture group) then only single value parameters would be\nallowed."),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"')'"),": A fixed closing brace for the end of the parameter list passed to the constructor of the type.\nAnother point to note in the CreateTypeToken implementation is the ",(0,o.yg)("inlineCode",{parentName:"li"},"getGuidance")," method. This is catching two scenarios where they have\ndefined a new token but are missing either the start or end of the brackets for the list of parameters.")),(0,o.yg)("p",null,"Now that we have both tokens to create an instance of a type and the token class used to represent the type itself, it's time to start\nlinking them up together. Let's start with writing the ",(0,o.yg)("inlineCode",{parentName:"p"},"process")," method on the CreateTypeToken. I'll break this into two sections\nas there are a few things we need to do:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-java"},'@Override\nprotected List<Token<?>> process(LARFParser parser, LARFContext context, LARFConfig config) {\n    //Validate values found in capture groups    \n    String name = getTokenGroups().get(0).getFlatTokens().get(0).getValue(String.class);\n    if (!context.getPrototypes().contains(name)) {\n        throw new ParserException("No registered type found with the name " + name);\n    }\n    Token<?> result = (Token<?>) context.getContextObject(name);\n    if (Objects.isNull(result) || !(result instanceof MyTypeToken)) {\n        throw new ParserException(String.format("Target type \'%s\' is null or not a MyTypeToken!",\n                result.getClass().getSimpleName()));\n    }\n    Token<?> clonedToken = ((TypeToken)result).createInstance(parser, context, config, name);\n    //...\n}\n')),(0,o.yg)("p",null,"The first step is to verify the values we find in the capture group. First we'll verify that the first capture group (type name) is a String.\nThis should be enforced by the Lexer, but it never hurts to put in your own validation. Next, we'll retrieve our type from context. We did\nthis earlier on with the ",(0,o.yg)("inlineCode",{parentName:"p"},"context.set(typeName, this, VariableType.PROTOTYPE);"),". The next check simply verifies that it is not null and is\nthe same type as our type token class. Finally, we invoke the ",(0,o.yg)("inlineCode",{parentName:"p"},"createInstance")," method on our type token class and whose responsibility it\nis to create a new instance of itself. If you wish to see the implementation of that method, please see the ",(0,o.yg)("a",{parentName:"p",href:"/docs/toolkit/tokens/instances#creating-a-clone"},"Creating an Instance"),"."),(0,o.yg)("p",null,"Let's now take a look at the second part to the ",(0,o.yg)("inlineCode",{parentName:"p"},"process")," method:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-java"},'protected List<Token<?>> process(LARFParser parser, LARFContext context, LARFConfig config) {\n    //...\n    try {\n        //Part 1        \n        parser.tokenStart(clonedToken);\n        if (getTokenGroups().size() > 1 && !getTokenGroups().get(1).getTokens().isEmpty()) {\n            //Part 2\n            List<Token<?>> actualParams = getTokenGroups().get(1).getTokens().stream()\n                    .map(tg -> {\n                        if (tg instanceof TokenGroup)\n                            return parser.processExpression(((TokenGroup)tg).getTokens(), context);\n                        return tg;\n                    }).collect(Collectors.toList());\n            List<Token<?>> expectedParams = result.getTokenGroups().get(1).getFlatTokens();\n            //Part 3\n            if (actualParams.size() != expectedParams.size()) {\n                throw new ParserException(String.format("Could not invoke default type " +\n                                " constructor as parameter requirement not met. Found " + \n                                "%d instead of expected %d", \n                        getTokenGroups().get(1).getTokens().size(),\n                        result.getTokenGroups().get(1).getTokens().size()));\n            }\n            //Part 4\n            for (int i = 0; i < expectedParams.size(); i++) {\n                context.set(expectedParams.get(i).getValue(String.class), \n                    actualParams.get(i).getValue());\n            }\n        }\n    } finally {\n        parser.tokenEnd(clonedToken, false);\n    }\n    //Part 5\n    clonedToken.setVariableType(VariableType.INSTANCE);\n    return Collections.singletonList(clonedToken);\n}\n')),(0,o.yg)("p",null,"There is quite a lot going on here in this second section. I've broken in down into parts (see comments) and will describe it below:"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Part 1"),": Firstly we wrap the entire next stage in a ",(0,o.yg)("inlineCode",{parentName:"li"},"try...finally")," with a ",(0,o.yg)("inlineCode",{parentName:"li"},"parser.startToken(clonedToken);")," and matching ",(0,o.yg)("inlineCode",{parentName:"li"},"parse.tokenEnd(clonedToken, false);"),".\nThis part is important as this tells the parser to keep the instance and it's resources in scope. These are invoked traditionally by the\nparser itself to manage scope and cleanup resources of tokens after completion. Here though we're artificially calling it to ensure\nthat the instance is added and kept part of the runtime stack. The ",(0,o.yg)("inlineCode",{parentName:"li"},"tokenEnd(..., false);")," informs the parser not to clean up associated\nresources upon completion. The next if block only executes the main code-block if parameters are present."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Part 2"),": This fetches not only the parameter values passed to our CreateTypeToken e.g. ",(0,o.yg)("inlineCode",{parentName:"li"},"new MyType(1,2,3)")," but also the expected\nparameters from our original type definition e.g. ",(0,o.yg)("inlineCode",{parentName:"li"},"type MyType(a,b,c) { ... }"),". From this we'll have both our parameters ",(0,o.yg)("inlineCode",{parentName:"li"},"[1,2,3]"),"\nand the expected ",(0,o.yg)("inlineCode",{parentName:"li"},"[a,b,c]"),"."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Part 3"),": This verifies that the expected and provided parameters match. If not then we throw a runtime error as the parameter\nrequirement was not met."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Part 4"),": We loop through the expected parameters and add each into context. Each of these will be associated with our new instance."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Part 5"),": Finally we set the type of token to ",(0,o.yg)("inlineCode",{parentName:"li"},"VariableType.INSTANCE")," and return it.")),(0,o.yg)("h3",{id:"creating-a-clone"},"Creating a Clone"),(0,o.yg)("p",null,"Before we dive in, let's remind ourselves about the token groups and what they represent in the pattern:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},"'type' val:String ( '(' ( val:String ','? )+? ')' )? ( '<-' val:String )? [ multiLine ]\n")),(0,o.yg)("p",null,"Token Groups (0-indexed):"),(0,o.yg)("ol",{start:0},(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"val:String")," = The name of the type"),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"( '(' ( val:String ','? )+? ')' )?")," = An optional bracketed list of parameters passed to the type"),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"( '<-' val:String )?")," = An optional ",(0,o.yg)("inlineCode",{parentName:"li"},"<-")," notation used for extending other types e.g. ",(0,o.yg)("inlineCode",{parentName:"li"},"type MyType <- ParentType"),"."),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"[ multiLine ]")," = A multi-line code block")),(0,o.yg)("p",null,"Using this, let's look at the implementation of the ",(0,o.yg)("inlineCode",{parentName:"p"},"createInstance")," method in our MyTypeToken class called from the CreateTypeToken\n",(0,o.yg)("inlineCode",{parentName:"p"},"process")," method. This is the longest of our methods and as such I'll split the description into three sections. This is because we first\nneed to identify type dependencies (for inheritance), copy across those resources to a temporary body group and then set the correct scope\nand modifiers before storing to context. Let's look at the first part:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-java"},"@Override\npublic Token<?> createInstance(LARFParser parser, LARFContext context, LARFConfig config) {\n    //Part 1\n    TypeToken clonedToken = (TypeToken) clone();\n    List<Token<?>> dependencies = new ArrayList<>();\n    for (String dependency : clonedToken.getDependencies()) {\n        //Part 3\n        config.getErrorHandlers().stream()\n                .filter(eh -> eh.canHandle(dependency))\n                .findFirst()\n                .ifPresent(l -> \n                    clonedToken.setValue(getTokenGroups().get(2).getFlatTokens().get(0)));\n        //Part 4\n        if (Objects.isNull(clonedToken.getValue())) {\n            Object found = context.getContextObject(dependency);\n            if (Objects.isNull(found)) {\n                throw new ParserException(String.format(\"Unknown parent object '%s' declared \" +\n                        \"for type '%s'\", dependency, getTypeName()));\n            }\n            dependencies.add((Token<?>) found);\n        }\n    }\n    //Part 5\n    if (dependencies.stream().anyMatch(d -> d instanceof ErrorInstance)) {\n        //If any of the parents are an error then set error parser flag\n        addParserFlag(ParserFlag.ERROR);\n    }        \n    //...\n}\n\n@Override\npublic String getTypeName() {\n    return getTokenGroups().get(0).getFlatTokens().get(0).getValue(String.class);\n}\n\n@Override\npublic List<String> getDependencies() {\n    //Part 2\n    List<Token<?>> parents = getTokenGroups().get(2).getFlatTokens();\n    return parents.stream()\n            .map(Token::getValue)\n            .filter(Objects::nonNull)\n            .map(Object::toString)\n            .collect(Collectors.toList());\n}\n")),(0,o.yg)("p",null,"Let's look at each part as it would be executed:"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Part 1"),": The current type token is cloned and a dependency list is created. This will be used to store all upstream dependencies which\nhave directly (or indirectly) declared."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Part 2"),": This is another of the methods we implemented from the TokenInstance class. This simply maps the list of types declared in\nour inheritance list. For our case you can only declare a single type, but it returns a list should interface equivalents also be included\nor... multiple inheritance. I would not recommend the latter, but new languages are there to push boundaries and established norms."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Part 3"),": This part dives into Error Handling and what happens if a defined type extends either a checked or unchecked error within the\nlanguage. We first try and find a match for the type of error we're inheriting from which will dictate how the parser handle it. To do this\nwe attempt to find a matching error handler against the name and set it as the value. You'll notice that when we defined our type token\n(",(0,o.yg)("inlineCode",{parentName:"li"},"public class MyTypeToken extends Token<Token<?>>"),") it used a generic type of ",(0,o.yg)("inlineCode",{parentName:"li"},"Token<?>"),". This was solely done to store this error handler.\nThis is done so that when the error is thrown, this error handler instance can be used to create the associated error type using the contained\nproperties. For more information, please see ",(0,o.yg)("a",{parentName:"li",href:"/docs/toolkit/error-handling"},"Error Handling"),"."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Part 4"),": The final part in this section checks to see whether an error handler has been found and set. If not then the current dependency\nis searched for in context. If not found then an error is thrown, but otherwise is added to the list of dependencies for use later."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Part 5"),": Related to Part 2, if this type inherits from a mapped error then we set the parser flag against this token. This tells the\nparser to handle this token in a special way. For more information on parser flags, please see ",(0,o.yg)("a",{parentName:"li",href:"/docs/toolkit/parser/parser-flags"},"Parser Flags"),".")),(0,o.yg)("p",null,"Let's look at the next part which deals processing those dependencies:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-java"},'@Override\npublic Token<?> createInstance(LARFParser parser, LARFContext context, LARFConfig config, \n                               String typeName) {\n    //...\n    //Part 1\n    TokenGroup bodyGroup = new TokenGroup();\n    if (getTokenGroups().get(3).getTokens().size() == 1) {\n        Token<?> found = clonedToken.getTokenGroups().get(3).getTokens().get(0);\n        if (!found.getTokenGroups().isEmpty()) {\n            bodyGroup.getTokens().addAll(found.getTokenGroups().get(0).getFlatTokens());\n        }\n    } else {\n        throw new ParserException(String.format("Expected single token which is either a " +\n                        "MultiLine or SingleLine token! Instead found %d being [%s]", \n                        getTokenGroups().get(3).getTokens().size(),\n                        Stream.of(getTokenGroups().get(3).getTokens()).map(o ->\n                                o.getClass().getSimpleName()).collect(Collectors.joining(","))));\n    }\n    //Part 2\n    bodyGroup.getTokens().forEach(t -> t.setOriginalParent(typeName));\n    for (Token<?> dependency : dependencies) {\n        if (!(dependency instanceof TokenInstance)) {\n            throw new ParserException(String.format("Expected parent to be of type \'TokenInstance\'" +\n                    " but instead found \'%s\'", dependency.getClass().getSimpleName()));\n        }\n        TokenInstance parentType = (TokenInstance) dependency;\n        //Part 3\n        verifyParentGroupParameters(parentType);\n        TokenGroup parentTokenGroup = parentType.getBodyGroup();\n        if (!parentTokenGroup.getTokens().isEmpty()) {\n            Token<?> body = parentTokenGroup.getTokens().get(0);\n            if (!(body instanceof MultiLineToken)) {\n                throw new ParserException(String.format("Expected type to have a body section of " +\n                        "type \'MultiLineToken\' but instead found \'%s\'", \n                        body.getClass().getSimpleName()));\n            }\n            TokenGroup parentTokens = parentTokenGroup.findGroupWithTokens(true)\n                    .orElse(new TokenGroup());\n            parentTokens.getTokens().forEach(t -> t.setOriginalParent(parentType.getTypeName()));\n            bodyGroup.getTokens().addAll(parentTokens.getTokens());\n        }\n    }\n    //...\n}\n')),(0,o.yg)("p",null,"There are three main parts to this section:"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Part 1"),": This creates the body group, to which all resources from the current type and it's parents (direct or indirect) are\nadded. If no body is provided then an error is thrown."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Part 2"),": Loops through all child resources in the body of the current type (not inherited) and sets the original parent value.\nThis is used for tracability for error handling. We then start a loop of the dependencies to which this type inherits from and\nperforms a check to verify that they are token instances (types). If so, we then store the current dependency to a TokenInstance\nvariable called parentType."),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Part 3"),": The final part firstly validates the parameters passed to this type match any parent type requirements if they exist.\nFor example, if we have a ",(0,o.yg)("inlineCode",{parentName:"li"},"ParentType")," which declares a parameter ",(0,o.yg)("inlineCode",{parentName:"li"},"d"),", we expect a ",(0,o.yg)("inlineCode",{parentName:"li"},"ChildType")," to reflect that in its own\nparameters e.g. ",(0,o.yg)("inlineCode",{parentName:"li"},"type ChildType(a,b,c,d) <- ParentType { ... }")," I won't provide the full code for this here, but but this can be\nfound in ",(0,o.yg)("a",{parentName:"li",href:"/docs/examples/slop"},"this")," example project. The next part is fetches the parent tokens body tokens, associates the\ncorrect parent to them and adds them to the current body group. This ensures accessibility of parent type resources from our current\ntype. ")),(0,o.yg)("p",null,"Resource scoping will happen in the final part which we'll look at now:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-java"},"@Override\npublic Token<?> createInstance(LARFParser parser, LARFContext context, LARFConfig config, \n                               String typeName) {\n    //...\n    try {\n        parser.tokenStart(clonedToken);\n        for (Token<?> token : bodyGroup.getTokens()) {\n            if (!token.isExpression() && token.getVariableName().isPresent()) {\n                List<TokenModifier> modifiers = new ArrayList<>();\n                String dataType = null;\n                if (token instanceof TypedReference) {\n                    modifiers = token.getModifiers(config);\n                    dataType = ((TypedReference) token).getDataType();\n                }\n                context.set(token.getVariableName().get(), token, dataType, modifiers);\n            } else {\n                parser.processExpression(Collections.singletonList(token), context);\n            }\n        }\n    } finally {\n        parser.tokenEnd(clonedToken, false);\n    }\n    return clonedToken;\n}\n")),(0,o.yg)("p",null,"The final part of this method is relatively simple. Similar to what we did with our CreateTypeToken, we also use the ",(0,o.yg)("inlineCode",{parentName:"p"},"try...finally"),"\nto manually set the current scope of the clonedToken to be active. This is so that when a value is set to context, it is assigned\nto the correct token (in our case the TypeToken instance). It loops through each body token and if it can be identified as a variable\nassociated with our type, we fetch the modifiers and data type to store it into context. Alternatively, for everything which is\nnot a variable, constant or attribute we defer execution to the parser."),(0,o.yg)("h3",{id:"handling-type-interactions"},"Handling Type Interactions"),(0,o.yg)("p",null,"As with most type interactions, they require other tokens to work. In most languages you can call a type's resources using an object\norientatd approach. Typically this is using the names of the object and sub-level resources using a delimiter. For example:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},"myObject.aMethod();\nmyObject.a\n")),(0,o.yg)("p",null,"We will mimic this functionality by introducing three new tokens being FieldToken, InvocationToken and FunctionToken. I won't take\nyou through the full implementation, but will provide a brief overview of each:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-java"},"public class FieldToken extends Token<Void> {\n    //...\n    @Override\n    public String getPattern() {\n        return \"( val '.'? )+\";\n    }\n    //...\n}\n")),(0,o.yg)("p",null,"The FieldToken places all captured values into a single token group that is repeatable. These values are separated by an optional\n",(0,o.yg)("inlineCode",{parentName:"p"},".")," character. The next token we'll need is the InvocationToken which will be reponsible for invoking methods:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-java"},"public class InvocationToken extends Token<Void> {\n    //...\n    @Override\n    public String getPattern() {\n        return \"val:String '(' ( expr ','? )+ ')'\";\n    }\n    //...\n}\n")),(0,o.yg)("p",null,"This captures the name of the method to invoke and captures a list of parameters. The final token is a FunctionToken which uses a\nspecial interface called TokenParameters:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-java"},"public class FunctionToken extends Token<Void> implements TokenParameters {\n    //...\n    @Override\n    public String getPattern() {\n        return \"'func' val '(' ( val ','? )+ ')' ( [ throws ] )? [ singleLine, multiLine ]\";\n    }\n\n    public List<Token<?>> process(LARFParser parser, LARFContext context, LARFConfig config, \n                                  List<Token<?>> providedParams) { ... }\n    //...\n}    \n")),(0,o.yg)("p",null,"The function token starts with a ",(0,o.yg)("inlineCode",{parentName:"p"},"func")," keyword and then uses a single capture group for the name. It then captures a group\nof single value parameters. This is because it's a typeless language, but if you were opting for Typed then you'd simply use\n",(0,o.yg)("inlineCode",{parentName:"p"},"'(' ( [ typedVariable ] ','? )+ ')'")," with ",(0,o.yg)("inlineCode",{parentName:"p"},"typedVariable")," being the name of your Typed value token. Moving on in the\npattern it then defined a single capture group for a ",(0,o.yg)("inlineCode",{parentName:"p"},"throws")," token which will be used to capture thrown errors. Finally it\nwill use a grammar branch where you can define either single or multi-line body implementation."),(0,o.yg)("p",null,"You'll also notice that as part of the TokenParameters, there is a new ",(0,o.yg)("inlineCode",{parentName:"p"},"process")," method which contains an additional set of\nparameters. This will be called from the InvocationToken to pass the parameter values to the FunctionToken. For more information\non creating Functions along with the InvocationToken and TokenParameters interface, please see ",(0,o.yg)("a",{parentName:"p",href:"/docs/toolkit/tokens/functions"},"here"),". With these\nand everything we've written up until now, the following can now be processed:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},"type MyType(a,b,c) {\n    func aMethod() {\n        return a + b + c;\n    }\n}\n\nanObject = new MyType(1,2,3);\nanObject.aMethod();\n")),(0,o.yg)("p",null,"The FieldToken will work in parallel with the InvocationToken to handle the ",(0,o.yg)("inlineCode",{parentName:"p"},"anObject.aMethod();")," call. Hierachically, these values would\nbe captured in the FieldToken as the following:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},'0: TokenGroup\n  - ReferenceToken("anObject")\n  - InvocationToken("aMethod")\n      0: TokenGroup\n        (Empty Parameter Group)\n')),(0,o.yg)("p",null,"When the FieldToken's ",(0,o.yg)("inlineCode",{parentName:"p"},"process")," is excuted, it would fetch from context the value of first token value (",(0,o.yg)("inlineCode",{parentName:"p"},'"anObject"'),") from context.\nSince that is found to be a TokenInstance, we'll store that as context for the next value which is the InvocationToken. This token is\nsolely there to handle function invocations."))}g.isMDXComponent=!0},5468:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/instances-cd01b9941ae6094cd1296958e16c2c2a.jpg"}}]);