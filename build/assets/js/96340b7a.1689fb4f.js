"use strict";(self.webpackChunklarf_site=self.webpackChunklarf_site||[]).push([[2437],{5680:(e,n,t)=>{t.d(n,{xA:()=>c,yg:()=>g});var o=t(6540);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,o,a=function(e,n){if(null==e)return{};var t,o,a={},r=Object.keys(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var l=o.createContext({}),p=function(e){var n=o.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},c=function(e){var n=p(e.components);return o.createElement(l.Provider,{value:n},e.children)},u="mdxType",h={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},d=o.forwardRef((function(e,n){var t=e.components,a=e.mdxType,r=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),u=p(t),d=a,g=u["".concat(l,".").concat(d)]||u[d]||h[d]||r;return t?o.createElement(g,i(i({ref:n},c),{},{components:t})):o.createElement(g,i({ref:n},c))}));function g(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var r=t.length,i=new Array(r);i[0]=d;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[u]="string"==typeof e?e:a,i[1]=s;for(var p=2;p<r;p++)i[p]=t[p];return o.createElement.apply(null,i)}return o.createElement.apply(null,t)}d.displayName="MDXCreateElement"},1395:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>p});var o=t(8168),a=(t(6540),t(5680));const r={sidebar_position:1},i="Token Overview",s={unversionedId:"toolkit/tokens/token-overview",id:"toolkit/tokens/token-overview",title:"Token Overview",description:"Tokens",source:"@site/docs/toolkit/tokens/token-overview.md",sourceDirName:"toolkit/tokens",slug:"/toolkit/tokens/token-overview",permalink:"/docs/toolkit/tokens/token-overview",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/toolkit/tokens/token-overview.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Configuration",permalink:"/docs/toolkit/configuration"},next:{title:"Functions",permalink:"/docs/toolkit/tokens/functions"}},l={},p=[{value:"How Tokens are used",id:"how-tokens-are-used",level:3}],c={toc:p},u="wrapper";function h(e){let{components:n,...r}=e;return(0,a.yg)(u,(0,o.A)({},c,r,{components:n,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"token-overview"},"Token Overview"),(0,a.yg)("p",null,(0,a.yg)("img",{alt:"Tokens",src:t(4868).A,width:"1468",height:"328"})),(0,a.yg)("h3",{id:"how-tokens-are-used"},"How Tokens are used"),(0,a.yg)("admonition",{title:"Optional Reading",type:"tip"},(0,a.yg)("p",{parentName:"admonition"},"The following is not required reading if you are simply looking to get up and running. This is those interested in\nlearning how LARF uses tokens to parse expressions. If you would like more information on the Token class\nitself then I would recommend looking at the ",(0,a.yg)("a",{parentName:"p",href:"/docs/tutorial/in-the-beginning#token-class"},"In the beginning"))),(0,a.yg)("p",null,"LARF takes a unique approach to tokens in that in many language tools, tokens represent keywords, operators and literals.\nAs such, if you had the expression ",(0,a.yg)("inlineCode",{parentName:"p"},"int i = 1;"),", this would be broken up into ",(0,a.yg)("inlineCode",{parentName:"p"},"int"),", ",(0,a.yg)("inlineCode",{parentName:"p"},"i"),", ",(0,a.yg)("inlineCode",{parentName:"p"},"="),", ",(0,a.yg)("inlineCode",{parentName:"p"},"1")," and ",(0,a.yg)("inlineCode",{parentName:"p"},";"),".\nThe parser then constructs an Abstract Syntax Tree (AST) to represent the hierarchical structure of the program with\nnodes in the tree corresponding to language constructs e.g. expressions, statements, functions. LARF on the other hand\nabstracts this so that those constructs become the tokens. Let's look at an example: "),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},"for (int i = 0;i < 10;i++) { \n    if (i % 2 == 0) \n        PRINT(i);\n}\n")),(0,a.yg)("p",null,'When the Lexer is run against this expression, it uses several base tokens found within the core project that split the\nString into what would normally be called "tokens". These are named NonToken and TokenValue and are registered in the\nLARFConfig.initBaseTokens(). These can be overriden should you so wish, but for most this will cover the majority of\nscenarios. The TokenValue class represents every alphanumeric value, whereas the NonToken caters to everything else.\nAs such, when the Lexer reads the first line, it will process them as:'),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},'TokenValue(value = "for")\nNonToken(value = "(")\nTokenValue(value = "int")\nTokenValue(value = "i")\nNonToken(value = "=")\n...\n')),(0,a.yg)("p",null,"All values at this stage are read as Strings and stored as such in these tokens. The next stage is where your custom\nset of language tokens are used. When you setup your language and define a config file, you'll register the tokens\nthat make up your language using the following:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},"@Override\nprotected void initTokenHandlers() {\n    setNullToken(new NullToken());\n    //...\n}\n")),(0,a.yg)("p",null,"These token handlers are scanned for a match against the current token. For example, if we take a look at the definition\nof a ForToken, we might see something similar to the following:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},"public class ForToken extends Token<Void> {\n    //...\n\n    @Override\n    public PatternType getPatternType() {\n        return PatternType.GRAMMAR;\n    }\n\n    @Override\n    public String getPattern() {\n        return \"'for' '(' [ fixedLoop, variableLoop ] ')' [ singleLine, multiLine ]\";\n    }\n\n    //...\n}\n")),(0,a.yg)("p",null,"LARF will look for a match against either the regular expression or grammar (as above) to see if a match is found. In\nthe above case we can see a ",(0,a.yg)("inlineCode",{parentName:"p"},"'for'")," static syntax value that matches the first token in the expression (Please see ",(0,a.yg)("a",{parentName:"p",href:"./grammar"},"Grammar"),' for more information).\nIf multiple token handlers are matched, it will attempt to use a look-ahead mechanism to make a "best guess", but if\nthat still fails then an error will be thrown by the Lexer due to token ambuiguity. In our case we only have one Token\nwhich represents a for statement as a match. As such, the Lexer will create a new instance of this and push it onto the\nstack. '),(0,a.yg)("p",null,"This process continues until it reaches the first grammar branch where it can either be a fixed or variable loop\nvariant of the loop. This is where these references are used to match the next token against one of these references.\nThe reference labels ",(0,a.yg)("inlineCode",{parentName:"p"},"fixedLoop")," and ",(0,a.yg)("inlineCode",{parentName:"p"},"variableLoop")," are specified by using the Token constructor name parameter. For\nexample, if we look at the FixedLoopToken, we can see the following:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},"public class FixedLoopToken extends Token<Void> implements TokenCallback {\n\n    public FixedLoopToken() {\n        super(\"fixedLoop\", null, TokenType.SECONDARY);\n    }\n\n    @Override\n    public PatternType getPatternType() {\n        return PatternType.GRAMMAR;\n    }\n\n    @Override\n    public String getPattern() {\n        return \"expr ';' expr ';' expr\";\n    }\n\n    //...\n}\n")),(0,a.yg)("p",null,"You can see that there are three ",(0,a.yg)("inlineCode",{parentName:"p"},"expr")," grammar tokens which represent a capture group or one or more tokens. How then\ndoes it know whether to choose this FixedLoopToken over the VariableLoopToken. Let's first compare the above to a\nVariableLoopToken implementation:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},'public class VariableLoopToken extends Token<Void> implements TokenCallback {\n\n    public VariableLoopToken() {\n        super("variableLoop", null, TokenType.SECONDARY);\n    }\n\n    @Override\n    public PatternType getPatternType() {\n        return PatternType.GRAMMAR;\n    }\n\n    @Override\n    public String getPattern() {\n        return "val \':\' expr";\n    }\n\n    //...\n}\n')),(0,a.yg)("admonition",{title:"Token Types",type:"tip"},(0,a.yg)("p",{parentName:"admonition"},"When defining a Token you can specify whether it is a PRIMARY or SECONDARY type. The former is the default\nand means it can be created from the expression String without any dependence on another Token. The SECONDARY type\nmeans that it cannot be used on its own and will result in an error if this is attempted. For example, in the\nC / Java language, you cannot define a code-block body e.g. ",(0,a.yg)("inlineCode",{parentName:"p"},"{ ... }")," without an associated statement to which\nit is associated (class, function, loop etc). In the example above, we would not define the loop definition\nwithout the associated ForToken, hence it being a secondary type.")),(0,a.yg)("p",null,"Let's go back to the expression that is currently being parsed and compare:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},"for (int i = 0;i < 10;i++) {\n    //...\n}\n")),(0,a.yg)("p",null,"LARF will keep processing and adding tokens to a short-term processing store until it has identified the parent to which\nthese tokens belong. In our case we find a match when the first semi-colon (",(0,a.yg)("inlineCode",{parentName:"p"},";"),") is found. This immediately identifies\nthe FixedLoopToken as being the correct branch as the VariableLoop is expecting only a single value and a colon (",(0,a.yg)("inlineCode",{parentName:"p"},":"),").\nA new instance of this is then created and pushed onto the stack. Those tokens which were captured prior to the semi-colon\nare then added to the first capture group and the token positions are updated. "),(0,a.yg)("p",null,"Once a token has identified itself as being complete (all grammar token requirements are fulfilled), an event is triggered\nin the lexer. The complete token is removed from the stack and either added to the parent item if the stack is not empty,\nor added to short-term memory. This process completes until all tokens are read from the expression and returned to the\nLARFProcessor class. The result of this can then be persisted to storage to run later or to execute immediately."))}h.isMDXComponent=!0},4868:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/tokens-52768d6ffc90a4347dba59db5213f9f8.jpg"}}]);